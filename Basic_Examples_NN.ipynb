{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrTDbW/c3tFcQ/fmW8Wo6H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antonsysoev/DeepLearning/blob/main/Basic_Examples_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THHbIrLNuUXA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переменная в TensorFlow — это некий буфер в памяти, который содержит тензоры.\n",
        "Переменные нужно явным образом инициализировать. Чтобы объявить переменную,\n",
        "нужно задать способ ее инициализации; при желании можно также назначить\n",
        "ей имя, на которое можно будет потом ссылаться. Например:"
      ],
      "metadata": {
        "id": "UuqpDAElvJXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = tf.Variable(tf.random.normal([3, 2], mean=0.0, stddev=0.4), name='weights')\n",
        "b = tf.Variable(tf.zeros([2]), name='biases')"
      ],
      "metadata": {
        "id": "XOlYZBybuVVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом коде мы объявили две переменные: w с именем weights и b с именем biases.\n",
        "Для переменных можно явным образом указать, где именно им нужно находиться\n",
        "в памяти; например, если вы хотите объявить переменную на первой (нулевой)\n",
        "видеокарте, это можно сделать так:"
      ],
      "metadata": {
        "id": "VNpgbDWevPMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  w = tf.Variable(tf.random.normal([3, 2], mean=0.0, stddev=0.4), name='weights')"
      ],
      "metadata": {
        "id": "YCK5Y38EufOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В TensorFlow реализован полный набор операций над тензорами из NumPy\n",
        "с поддержкой матричных вычислений над массивами разной формы и конвертирования\n",
        "между этими формами (broadcasting). Например, в реальных задачах часто\n",
        "возникает необходимость к каждому столбцу матрицы поэлементно добавить один\n",
        "и тот же вектор. В TensorFlow это делается самым простым из возможных способов:"
      ],
      "metadata": {
        "id": "wuM8f5aJv2bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = tf.Variable(tf.random.normal([10, 100], mean=0.0, stddev=0.4), name='matrix')\n",
        "v = tf.Variable(tf.random.normal([100], mean=0.0, stddev=0.4), name='vector')\n",
        "result = m + v"
      ],
      "metadata": {
        "id": "6Zfdkr4Sv24A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_transform(vec,shape):\n",
        "  w = tf.Variable(tf.random.normal(shape, mean=0.0, stddev=1.0), name='matrix')\n",
        "  return tf.matmul(vec,w)"
      ],
      "metadata": {
        "id": "6SBf_bVKxO7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "n_samples, batch_size, num_steps = 1000,100,30000\n",
        "\n",
        "# y = 2x + 1\n",
        "\n",
        "X_data = np.random.uniform(1,10,(n_samples,1))\n",
        "y_data = 2 * X_data + 1 + np.random.normal(0,2,(n_samples,1))\n",
        "\n",
        "X = tf.compat.v1.placeholder(tf.float32,shape=(batch_size,1))\n",
        "y = tf.compat.v1.placeholder(tf.float32,shape=(batch_size,1))\n",
        "\n",
        "with tf.compat.v1.variable_scope('linear-regression'):\n",
        "  k = tf.Variable(tf.random.normal((1,1)), name = 'slope')\n",
        "  b = tf.Variable(tf.zeros((1,)), name = 'bias')\n",
        "\n",
        "y_pred = tf.matmul(X,k) + b\n",
        "loss = tf.reduce_sum((y-y_pred)**2)\n",
        "optimizer = tf.compat.v1.train.GradientDescentOptimizer(0.00001).minimize(loss)\n",
        "\n",
        "display_step = 100\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  sess.run(tf.compat.v1.global_variables_initializer())\n",
        "  for i in range(num_steps):\n",
        "    indices = np.random.choice(n_samples,batch_size)\n",
        "    X_batch, y_batch = X_data[indices], y_data[indices]\n",
        "    _, loss_val, k_val, b_val = sess.run([optimizer,loss,k,b],\n",
        "                                         feed_dict = {X:X_batch, y:y_batch})\n",
        "    if (i+1) % display_step == 0:\n",
        "      print('Эпоха %d: %.8f, k = %.4f, b = %.4f' %\n",
        "            (i+1, loss_val, k_val, b_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XARYNWyWxtWz",
        "outputId": "7eda2839-bba9-4c8c-c7ca-a758ff9728a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 100: 409.14382935, k = 2.0650, b = 0.5001\n",
            "Эпоха 200: 374.13916016, k = 2.0590, b = 0.5167\n",
            "Эпоха 300: 330.15701294, k = 2.0606, b = 0.5329\n",
            "Эпоха 400: 309.19104004, k = 2.0577, b = 0.5470\n",
            "Эпоха 500: 489.74005127, k = 2.0558, b = 0.5623\n",
            "Эпоха 600: 379.61108398, k = 2.0544, b = 0.5779\n",
            "Эпоха 700: 369.54577637, k = 2.0572, b = 0.5921\n",
            "Эпоха 800: 371.01528931, k = 2.0597, b = 0.6016\n",
            "Эпоха 900: 394.51525879, k = 2.0503, b = 0.6144\n",
            "Эпоха 1000: 312.49621582, k = 2.0451, b = 0.6284\n",
            "Эпоха 1100: 339.07272339, k = 2.0439, b = 0.6402\n",
            "Эпоха 1200: 386.43487549, k = 2.0389, b = 0.6469\n",
            "Эпоха 1300: 390.90298462, k = 2.0434, b = 0.6574\n",
            "Эпоха 1400: 368.90887451, k = 2.0490, b = 0.6701\n",
            "Эпоха 1500: 397.70520020, k = 2.0335, b = 0.6806\n",
            "Эпоха 1600: 238.56654358, k = 2.0419, b = 0.6914\n",
            "Эпоха 1700: 329.07550049, k = 2.0271, b = 0.6987\n",
            "Эпоха 1800: 428.91787720, k = 2.0381, b = 0.7097\n",
            "Эпоха 1900: 385.42565918, k = 2.0376, b = 0.7194\n",
            "Эпоха 2000: 351.43365479, k = 2.0394, b = 0.7277\n",
            "Эпоха 2100: 377.11306763, k = 2.0433, b = 0.7389\n",
            "Эпоха 2200: 433.68267822, k = 2.0396, b = 0.7452\n",
            "Эпоха 2300: 451.70626831, k = 2.0324, b = 0.7529\n",
            "Эпоха 2400: 449.54104614, k = 2.0336, b = 0.7597\n",
            "Эпоха 2500: 374.43179321, k = 2.0329, b = 0.7692\n",
            "Эпоха 2600: 299.78045654, k = 2.0317, b = 0.7766\n",
            "Эпоха 2700: 408.56625366, k = 2.0171, b = 0.7802\n",
            "Эпоха 2800: 373.11322021, k = 2.0370, b = 0.7906\n",
            "Эпоха 2900: 303.25747681, k = 2.0156, b = 0.7927\n",
            "Эпоха 3000: 359.84890747, k = 2.0219, b = 0.7991\n",
            "Эпоха 3100: 433.57525635, k = 2.0213, b = 0.8011\n",
            "Эпоха 3200: 458.49813843, k = 2.0236, b = 0.8068\n",
            "Эпоха 3300: 304.52319336, k = 2.0133, b = 0.8106\n",
            "Эпоха 3400: 349.63238525, k = 2.0283, b = 0.8194\n",
            "Эпоха 3500: 337.64108276, k = 2.0205, b = 0.8268\n",
            "Эпоха 3600: 347.89044189, k = 2.0090, b = 0.8282\n",
            "Эпоха 3700: 365.54217529, k = 2.0113, b = 0.8350\n",
            "Эпоха 3800: 396.43499756, k = 2.0240, b = 0.8421\n",
            "Эпоха 3900: 326.06631470, k = 2.0236, b = 0.8463\n",
            "Эпоха 4000: 358.35745239, k = 2.0219, b = 0.8514\n",
            "Эпоха 4100: 412.15536499, k = 2.0227, b = 0.8570\n",
            "Эпоха 4200: 384.33566284, k = 2.0009, b = 0.8577\n",
            "Эпоха 4300: 484.51535034, k = 2.0038, b = 0.8614\n",
            "Эпоха 4400: 437.42202759, k = 2.0095, b = 0.8594\n",
            "Эпоха 4500: 275.83941650, k = 2.0123, b = 0.8627\n",
            "Эпоха 4600: 328.06542969, k = 2.0104, b = 0.8636\n",
            "Эпоха 4700: 429.19686890, k = 2.0051, b = 0.8684\n",
            "Эпоха 4800: 299.82852173, k = 2.0144, b = 0.8721\n",
            "Эпоха 4900: 296.03497314, k = 2.0151, b = 0.8756\n",
            "Эпоха 5000: 378.72296143, k = 2.0174, b = 0.8764\n",
            "Эпоха 5100: 484.06784058, k = 2.0144, b = 0.8793\n",
            "Эпоха 5200: 357.81478882, k = 2.0139, b = 0.8823\n",
            "Эпоха 5300: 403.94464111, k = 2.0168, b = 0.8857\n",
            "Эпоха 5400: 349.84661865, k = 2.0057, b = 0.8879\n",
            "Эпоха 5500: 608.08447266, k = 2.0210, b = 0.8924\n",
            "Эпоха 5600: 356.69699097, k = 2.0189, b = 0.8945\n",
            "Эпоха 5700: 369.08929443, k = 2.0079, b = 0.8984\n",
            "Эпоха 5800: 413.64239502, k = 2.0090, b = 0.9021\n",
            "Эпоха 5900: 381.59790039, k = 2.0135, b = 0.9076\n",
            "Эпоха 6000: 415.55465698, k = 2.0056, b = 0.9090\n",
            "Эпоха 6100: 496.96240234, k = 2.0098, b = 0.9143\n",
            "Эпоха 6200: 326.73385620, k = 2.0147, b = 0.9139\n",
            "Эпоха 6300: 405.66567993, k = 2.0049, b = 0.9123\n",
            "Эпоха 6400: 364.89797974, k = 2.0099, b = 0.9154\n",
            "Эпоха 6500: 279.24627686, k = 2.0070, b = 0.9158\n",
            "Эпоха 6600: 351.24923706, k = 2.0150, b = 0.9161\n",
            "Эпоха 6700: 407.10424805, k = 2.0102, b = 0.9166\n",
            "Эпоха 6800: 395.30810547, k = 2.0091, b = 0.9180\n",
            "Эпоха 6900: 452.36508179, k = 2.0293, b = 0.9190\n",
            "Эпоха 7000: 445.34503174, k = 2.0118, b = 0.9187\n",
            "Эпоха 7100: 300.56811523, k = 2.0076, b = 0.9209\n",
            "Эпоха 7200: 345.02642822, k = 2.0128, b = 0.9246\n",
            "Эпоха 7300: 388.09170532, k = 2.0068, b = 0.9228\n",
            "Эпоха 7400: 317.12213135, k = 2.0143, b = 0.9235\n",
            "Эпоха 7500: 316.89184570, k = 2.0050, b = 0.9243\n",
            "Эпоха 7600: 264.60717773, k = 2.0118, b = 0.9264\n",
            "Эпоха 7700: 383.91403198, k = 2.0093, b = 0.9286\n",
            "Эпоха 7800: 403.04684448, k = 2.0032, b = 0.9244\n",
            "Эпоха 7900: 430.68539429, k = 2.0087, b = 0.9255\n",
            "Эпоха 8000: 506.25799561, k = 2.0104, b = 0.9251\n",
            "Эпоха 8100: 291.36254883, k = 2.0219, b = 0.9321\n",
            "Эпоха 8200: 334.08990479, k = 2.0030, b = 0.9312\n",
            "Эпоха 8300: 284.32235718, k = 2.0127, b = 0.9342\n",
            "Эпоха 8400: 407.45611572, k = 2.0139, b = 0.9357\n",
            "Эпоха 8500: 384.36141968, k = 2.0013, b = 0.9367\n",
            "Эпоха 8600: 271.72366333, k = 2.0019, b = 0.9357\n",
            "Эпоха 8700: 335.09075928, k = 2.0001, b = 0.9358\n",
            "Эпоха 8800: 493.18588257, k = 2.0078, b = 0.9391\n",
            "Эпоха 8900: 375.02801514, k = 2.0039, b = 0.9384\n",
            "Эпоха 9000: 381.24047852, k = 2.0129, b = 0.9386\n",
            "Эпоха 9100: 315.53146362, k = 2.0182, b = 0.9359\n",
            "Эпоха 9200: 419.43542480, k = 2.0071, b = 0.9350\n",
            "Эпоха 9300: 393.88650513, k = 1.9946, b = 0.9344\n",
            "Эпоха 9400: 325.04122925, k = 2.0142, b = 0.9396\n",
            "Эпоха 9500: 319.51144409, k = 2.0144, b = 0.9410\n",
            "Эпоха 9600: 391.26226807, k = 2.0007, b = 0.9414\n",
            "Эпоха 9700: 362.03189087, k = 2.0091, b = 0.9405\n",
            "Эпоха 9800: 427.70092773, k = 1.9929, b = 0.9382\n",
            "Эпоха 9900: 396.02893066, k = 2.0032, b = 0.9415\n",
            "Эпоха 10000: 267.25720215, k = 2.0091, b = 0.9422\n",
            "Эпоха 10100: 379.43954468, k = 2.0086, b = 0.9416\n",
            "Эпоха 10200: 311.70605469, k = 2.0111, b = 0.9432\n",
            "Эпоха 10300: 419.04333496, k = 2.0097, b = 0.9427\n",
            "Эпоха 10400: 429.41506958, k = 2.0118, b = 0.9464\n",
            "Эпоха 10500: 373.37286377, k = 2.0095, b = 0.9485\n",
            "Эпоха 10600: 532.53540039, k = 2.0020, b = 0.9467\n",
            "Эпоха 10700: 389.70907593, k = 2.0028, b = 0.9485\n",
            "Эпоха 10800: 458.88381958, k = 2.0075, b = 0.9487\n",
            "Эпоха 10900: 388.19296265, k = 2.0007, b = 0.9462\n",
            "Эпоха 11000: 354.85977173, k = 2.0066, b = 0.9441\n",
            "Эпоха 11100: 370.48852539, k = 1.9967, b = 0.9435\n",
            "Эпоха 11200: 416.83956909, k = 1.9957, b = 0.9422\n",
            "Эпоха 11300: 425.58624268, k = 2.0072, b = 0.9456\n",
            "Эпоха 11400: 393.57879639, k = 2.0164, b = 0.9470\n",
            "Эпоха 11500: 347.43234253, k = 2.0062, b = 0.9458\n",
            "Эпоха 11600: 330.96743774, k = 1.9965, b = 0.9456\n",
            "Эпоха 11700: 316.99197388, k = 2.0008, b = 0.9451\n",
            "Эпоха 11800: 444.77484131, k = 2.0059, b = 0.9462\n",
            "Эпоха 11900: 432.57720947, k = 2.0007, b = 0.9441\n",
            "Эпоха 12000: 352.05371094, k = 2.0125, b = 0.9466\n",
            "Эпоха 12100: 326.11380005, k = 2.0027, b = 0.9448\n",
            "Эпоха 12200: 343.48739624, k = 2.0118, b = 0.9469\n",
            "Эпоха 12300: 394.55371094, k = 1.9926, b = 0.9453\n",
            "Эпоха 12400: 423.53707886, k = 2.0040, b = 0.9475\n",
            "Эпоха 12500: 318.58691406, k = 2.0143, b = 0.9468\n",
            "Эпоха 12600: 461.84149170, k = 2.0045, b = 0.9457\n",
            "Эпоха 12700: 397.50219727, k = 2.0077, b = 0.9477\n",
            "Эпоха 12800: 369.24374390, k = 2.0041, b = 0.9481\n",
            "Эпоха 12900: 381.33425903, k = 1.9984, b = 0.9479\n",
            "Эпоха 13000: 340.95770264, k = 2.0036, b = 0.9468\n",
            "Эпоха 13100: 344.27014160, k = 2.0080, b = 0.9460\n",
            "Эпоха 13200: 382.60540771, k = 1.9977, b = 0.9461\n",
            "Эпоха 13300: 371.99392700, k = 2.0009, b = 0.9495\n",
            "Эпоха 13400: 418.88571167, k = 2.0172, b = 0.9530\n",
            "Эпоха 13500: 405.65042114, k = 2.0030, b = 0.9487\n",
            "Эпоха 13600: 457.24325562, k = 2.0042, b = 0.9504\n",
            "Эпоха 13700: 317.51116943, k = 1.9912, b = 0.9504\n",
            "Эпоха 13800: 384.65798950, k = 2.0007, b = 0.9498\n",
            "Эпоха 13900: 337.00985718, k = 2.0091, b = 0.9514\n",
            "Эпоха 14000: 485.68197632, k = 1.9982, b = 0.9496\n",
            "Эпоха 14100: 386.13488770, k = 1.9996, b = 0.9548\n",
            "Эпоха 14200: 415.65045166, k = 1.9886, b = 0.9532\n",
            "Эпоха 14300: 366.90209961, k = 1.9999, b = 0.9583\n",
            "Эпоха 14400: 319.25625610, k = 2.0023, b = 0.9580\n",
            "Эпоха 14500: 359.38085938, k = 1.9920, b = 0.9584\n",
            "Эпоха 14600: 360.14373779, k = 1.9986, b = 0.9589\n",
            "Эпоха 14700: 393.93933105, k = 1.9957, b = 0.9563\n",
            "Эпоха 14800: 348.67166138, k = 1.9932, b = 0.9547\n",
            "Эпоха 14900: 410.76742554, k = 2.0027, b = 0.9536\n",
            "Эпоха 15000: 391.03039551, k = 2.0088, b = 0.9544\n",
            "Эпоха 15100: 406.69949341, k = 2.0056, b = 0.9518\n",
            "Эпоха 15200: 487.26504517, k = 1.9969, b = 0.9486\n",
            "Эпоха 15300: 347.36230469, k = 2.0054, b = 0.9502\n",
            "Эпоха 15400: 345.46234131, k = 1.9997, b = 0.9478\n",
            "Эпоха 15500: 427.96737671, k = 2.0062, b = 0.9497\n",
            "Эпоха 15600: 358.93310547, k = 1.9965, b = 0.9482\n",
            "Эпоха 15700: 391.68081665, k = 2.0049, b = 0.9509\n",
            "Эпоха 15800: 308.08041382, k = 2.0077, b = 0.9490\n",
            "Эпоха 15900: 292.32623291, k = 2.0064, b = 0.9483\n",
            "Эпоха 16000: 351.37600708, k = 1.9962, b = 0.9491\n",
            "Эпоха 16100: 383.48648071, k = 2.0034, b = 0.9508\n",
            "Эпоха 16200: 476.24710083, k = 2.0058, b = 0.9500\n",
            "Эпоха 16300: 375.98837280, k = 1.9976, b = 0.9517\n",
            "Эпоха 16400: 398.65405273, k = 2.0041, b = 0.9553\n",
            "Эпоха 16500: 285.29769897, k = 1.9985, b = 0.9546\n",
            "Эпоха 16600: 347.63690186, k = 2.0050, b = 0.9564\n",
            "Эпоха 16700: 393.57388306, k = 2.0018, b = 0.9555\n",
            "Эпоха 16800: 420.32388306, k = 1.9990, b = 0.9542\n",
            "Эпоха 16900: 388.19552612, k = 2.0123, b = 0.9541\n",
            "Эпоха 17000: 448.89349365, k = 2.0015, b = 0.9506\n",
            "Эпоха 17100: 426.10140991, k = 2.0076, b = 0.9521\n",
            "Эпоха 17200: 386.32196045, k = 2.0047, b = 0.9522\n",
            "Эпоха 17300: 364.66848755, k = 2.0051, b = 0.9513\n",
            "Эпоха 17400: 294.10452271, k = 1.9976, b = 0.9502\n",
            "Эпоха 17500: 412.10366821, k = 1.9967, b = 0.9503\n",
            "Эпоха 17600: 387.34161377, k = 1.9983, b = 0.9490\n",
            "Эпоха 17700: 437.62475586, k = 1.9895, b = 0.9477\n",
            "Эпоха 17800: 401.36541748, k = 2.0072, b = 0.9506\n",
            "Эпоха 17900: 372.42449951, k = 2.0096, b = 0.9479\n",
            "Эпоха 18000: 403.80960083, k = 2.0015, b = 0.9481\n",
            "Эпоха 18100: 397.59106445, k = 1.9968, b = 0.9473\n",
            "Эпоха 18200: 406.06668091, k = 2.0135, b = 0.9522\n",
            "Эпоха 18300: 519.62713623, k = 2.0049, b = 0.9495\n",
            "Эпоха 18400: 326.37475586, k = 1.9965, b = 0.9469\n",
            "Эпоха 18500: 353.04675293, k = 1.9975, b = 0.9473\n",
            "Эпоха 18600: 446.87048340, k = 2.0186, b = 0.9508\n",
            "Эпоха 18700: 354.32452393, k = 1.9931, b = 0.9476\n",
            "Эпоха 18800: 338.80953979, k = 2.0007, b = 0.9502\n",
            "Эпоха 18900: 445.94085693, k = 2.0059, b = 0.9479\n",
            "Эпоха 19000: 450.81671143, k = 1.9955, b = 0.9481\n",
            "Эпоха 19100: 307.28271484, k = 2.0086, b = 0.9515\n",
            "Эпоха 19200: 442.22726440, k = 2.0058, b = 0.9519\n",
            "Эпоха 19300: 305.75369263, k = 2.0000, b = 0.9497\n",
            "Эпоха 19400: 432.06362915, k = 1.9925, b = 0.9514\n",
            "Эпоха 19500: 300.29577637, k = 2.0007, b = 0.9503\n",
            "Эпоха 19600: 427.88677979, k = 1.9927, b = 0.9493\n",
            "Эпоха 19700: 387.81860352, k = 1.9934, b = 0.9505\n",
            "Эпоха 19800: 360.74191284, k = 2.0053, b = 0.9553\n",
            "Эпоха 19900: 336.19323730, k = 2.0103, b = 0.9606\n",
            "Эпоха 20000: 579.69458008, k = 1.9984, b = 0.9582\n",
            "Эпоха 20100: 336.81524658, k = 2.0137, b = 0.9597\n",
            "Эпоха 20200: 394.52633667, k = 2.0133, b = 0.9589\n",
            "Эпоха 20300: 421.93469238, k = 2.0008, b = 0.9561\n",
            "Эпоха 20400: 387.21020508, k = 1.9944, b = 0.9578\n",
            "Эпоха 20500: 409.47305298, k = 2.0017, b = 0.9571\n",
            "Эпоха 20600: 540.35852051, k = 2.0122, b = 0.9576\n",
            "Эпоха 20700: 402.33731079, k = 2.0060, b = 0.9561\n",
            "Эпоха 20800: 305.57412720, k = 2.0012, b = 0.9561\n",
            "Эпоха 20900: 450.12768555, k = 2.0053, b = 0.9561\n",
            "Эпоха 21000: 399.78533936, k = 2.0210, b = 0.9593\n",
            "Эпоха 21100: 339.43664551, k = 1.9976, b = 0.9562\n",
            "Эпоха 21200: 499.19607544, k = 2.0013, b = 0.9576\n",
            "Эпоха 21300: 335.21853638, k = 2.0010, b = 0.9585\n",
            "Эпоха 21400: 403.78933716, k = 1.9953, b = 0.9541\n",
            "Эпоха 21500: 307.87835693, k = 1.9951, b = 0.9549\n",
            "Эпоха 21600: 323.41192627, k = 1.9977, b = 0.9532\n",
            "Эпоха 21700: 306.84399414, k = 2.0081, b = 0.9570\n",
            "Эпоха 21800: 327.26971436, k = 2.0129, b = 0.9569\n",
            "Эпоха 21900: 465.95227051, k = 2.0056, b = 0.9510\n",
            "Эпоха 22000: 289.55685425, k = 2.0011, b = 0.9503\n",
            "Эпоха 22100: 361.44155884, k = 1.9959, b = 0.9509\n",
            "Эпоха 22200: 301.38088989, k = 1.9995, b = 0.9523\n",
            "Эпоха 22300: 445.03244019, k = 2.0004, b = 0.9534\n",
            "Эпоха 22400: 298.04235840, k = 2.0120, b = 0.9527\n",
            "Эпоха 22500: 353.98056030, k = 1.9919, b = 0.9518\n",
            "Эпоха 22600: 472.76550293, k = 1.9929, b = 0.9532\n",
            "Эпоха 22700: 444.98941040, k = 2.0031, b = 0.9554\n",
            "Эпоха 22800: 346.50933838, k = 2.0026, b = 0.9552\n",
            "Эпоха 22900: 420.57958984, k = 2.0012, b = 0.9509\n",
            "Эпоха 23000: 326.05792236, k = 2.0002, b = 0.9501\n",
            "Эпоха 23100: 386.95123291, k = 2.0049, b = 0.9531\n",
            "Эпоха 23200: 495.40542603, k = 1.9972, b = 0.9515\n",
            "Эпоха 23300: 251.84217834, k = 2.0140, b = 0.9546\n",
            "Эпоха 23400: 341.14199829, k = 2.0094, b = 0.9567\n",
            "Эпоха 23500: 353.43444824, k = 1.9937, b = 0.9560\n",
            "Эпоха 23600: 296.07263184, k = 1.9975, b = 0.9581\n",
            "Эпоха 23700: 439.07092285, k = 2.0021, b = 0.9586\n",
            "Эпоха 23800: 389.39810181, k = 2.0124, b = 0.9606\n",
            "Эпоха 23900: 385.65869141, k = 1.9971, b = 0.9585\n",
            "Эпоха 24000: 305.28039551, k = 1.9924, b = 0.9588\n",
            "Эпоха 24100: 422.60760498, k = 1.9993, b = 0.9586\n",
            "Эпоха 24200: 359.08245850, k = 2.0070, b = 0.9590\n",
            "Эпоха 24300: 304.39089966, k = 1.9985, b = 0.9582\n",
            "Эпоха 24400: 427.25561523, k = 2.0024, b = 0.9576\n",
            "Эпоха 24500: 343.89532471, k = 1.9951, b = 0.9555\n",
            "Эпоха 24600: 367.94439697, k = 2.0089, b = 0.9566\n",
            "Эпоха 24700: 356.22396851, k = 1.9960, b = 0.9533\n",
            "Эпоха 24800: 402.85903931, k = 2.0042, b = 0.9550\n",
            "Эпоха 24900: 431.76602173, k = 2.0008, b = 0.9543\n",
            "Эпоха 25000: 429.27352905, k = 2.0042, b = 0.9551\n",
            "Эпоха 25100: 326.56500244, k = 2.0041, b = 0.9535\n",
            "Эпоха 25200: 358.31555176, k = 2.0006, b = 0.9527\n",
            "Эпоха 25300: 382.73052979, k = 1.9980, b = 0.9522\n",
            "Эпоха 25400: 438.70040894, k = 1.9946, b = 0.9502\n",
            "Эпоха 25500: 303.37597656, k = 2.0046, b = 0.9518\n",
            "Эпоха 25600: 394.20245361, k = 2.0062, b = 0.9539\n",
            "Эпоха 25700: 345.53109741, k = 1.9979, b = 0.9526\n",
            "Эпоха 25800: 425.75924683, k = 1.9952, b = 0.9535\n",
            "Эпоха 25900: 353.42584229, k = 2.0043, b = 0.9579\n",
            "Эпоха 26000: 425.20581055, k = 2.0070, b = 0.9550\n",
            "Эпоха 26100: 314.49176025, k = 2.0004, b = 0.9518\n",
            "Эпоха 26200: 474.79980469, k = 2.0000, b = 0.9524\n",
            "Эпоха 26300: 354.32855225, k = 1.9917, b = 0.9528\n",
            "Эпоха 26400: 408.78430176, k = 1.9957, b = 0.9541\n",
            "Эпоха 26500: 369.98703003, k = 2.0096, b = 0.9568\n",
            "Эпоха 26600: 416.98037720, k = 1.9947, b = 0.9563\n",
            "Эпоха 26700: 380.92892456, k = 1.9965, b = 0.9571\n",
            "Эпоха 26800: 338.73867798, k = 2.0042, b = 0.9609\n",
            "Эпоха 26900: 352.35897827, k = 2.0205, b = 0.9611\n",
            "Эпоха 27000: 294.68096924, k = 1.9988, b = 0.9572\n",
            "Эпоха 27100: 341.32556152, k = 2.0064, b = 0.9557\n",
            "Эпоха 27200: 310.10382080, k = 1.9958, b = 0.9530\n",
            "Эпоха 27300: 372.52444458, k = 2.0009, b = 0.9524\n",
            "Эпоха 27400: 387.25109863, k = 1.9989, b = 0.9532\n",
            "Эпоха 27500: 287.37759399, k = 1.9959, b = 0.9526\n",
            "Эпоха 27600: 355.61334229, k = 2.0080, b = 0.9512\n",
            "Эпоха 27700: 448.39205933, k = 2.0045, b = 0.9533\n",
            "Эпоха 27800: 282.56399536, k = 2.0042, b = 0.9523\n",
            "Эпоха 27900: 405.98739624, k = 1.9985, b = 0.9530\n",
            "Эпоха 28000: 299.30300903, k = 2.0073, b = 0.9570\n",
            "Эпоха 28100: 298.53302002, k = 2.0032, b = 0.9576\n",
            "Эпоха 28200: 370.82089233, k = 2.0075, b = 0.9570\n",
            "Эпоха 28300: 358.86001587, k = 2.0018, b = 0.9540\n",
            "Эпоха 28400: 384.99594116, k = 2.0013, b = 0.9552\n",
            "Эпоха 28500: 337.59271240, k = 1.9942, b = 0.9535\n",
            "Эпоха 28600: 325.11987305, k = 2.0102, b = 0.9540\n",
            "Эпоха 28700: 372.60778809, k = 2.0082, b = 0.9520\n",
            "Эпоха 28800: 505.02856445, k = 1.9946, b = 0.9502\n",
            "Эпоха 28900: 442.85260010, k = 1.9984, b = 0.9519\n",
            "Эпоха 29000: 396.08999634, k = 2.0003, b = 0.9522\n",
            "Эпоха 29100: 334.99902344, k = 2.0002, b = 0.9520\n",
            "Эпоха 29200: 398.26580811, k = 2.0053, b = 0.9539\n",
            "Эпоха 29300: 302.76788330, k = 2.0075, b = 0.9545\n",
            "Эпоха 29400: 367.56326294, k = 2.0020, b = 0.9530\n",
            "Эпоха 29500: 378.60134888, k = 1.9941, b = 0.9545\n",
            "Эпоха 29600: 324.56988525, k = 2.0097, b = 0.9579\n",
            "Эпоха 29700: 335.45422363, k = 1.9986, b = 0.9534\n",
            "Эпоха 29800: 358.65036011, k = 2.0046, b = 0.9534\n",
            "Эпоха 29900: 445.98565674, k = 2.0075, b = 0.9526\n",
            "Эпоха 30000: 337.47882080, k = 1.9963, b = 0.9488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Activation"
      ],
      "metadata": {
        "id": "Czf-Ngep1VQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logr = Sequential()\n",
        "logr.add(Dense(1,input_dim = 2, activation = 'sigmoid'))\n",
        "logr.compile(loss = 'binary_crossentropy', optimizer='sgd', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "8HJJOcRH3Rzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sampler(n,x,y):\n",
        "  return np.random.normal(size=[n,2])+[x,y]"
      ],
      "metadata": {
        "id": "-5UJzRwn3teF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_data(n=1000, p0=(-1,-1), p1=(1,1)):\n",
        "  zeros = np.zeros((n,1))\n",
        "  ones = np.ones((n,1))\n",
        "  labels = np.vstack([zeros,ones])\n",
        "  z_sample = sampler(n,x=p0[0], y=p0[1])\n",
        "  o_sample = sampler(n,x=p1[0], y=p1[1])\n",
        "  return np.vstack([z_sample,o_sample]), labels"
      ],
      "metadata": {
        "id": "VlfBWMFH38wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = sample_data()\n",
        "X_test, Y_test = sample_data(100)"
      ],
      "metadata": {
        "id": "3JAZVB_84j8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logr.fit(X_train, Y_train, batch_size=16, nb_epoch=100, verbose=1, validation_data=(X_test,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGIJzxJc43c4",
        "outputId": "db7a1fa2-e1b1-42ee-f21e-fa91c9b76410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 2000 samples, validate on 200 samples\n",
            "Epoch 1/100\n",
            "2000/2000 [==============================] - 0s 168us/sample - loss: 0.3133 - accuracy: 0.9080 - val_loss: 0.3212 - val_accuracy: 0.8750\n",
            "Epoch 2/100\n",
            "2000/2000 [==============================] - 0s 53us/sample - loss: 0.2768 - accuracy: 0.9190 - val_loss: 0.2953 - val_accuracy: 0.8750\n",
            "Epoch 3/100\n",
            "  16/2000 [..............................] - ETA: 0s - loss: 0.1549 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000/2000 [==============================] - 0s 64us/sample - loss: 0.2561 - accuracy: 0.9215 - val_loss: 0.2792 - val_accuracy: 0.8750\n",
            "Epoch 4/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.2429 - accuracy: 0.9225 - val_loss: 0.2682 - val_accuracy: 0.8700\n",
            "Epoch 5/100\n",
            "2000/2000 [==============================] - 0s 56us/sample - loss: 0.2338 - accuracy: 0.9245 - val_loss: 0.2603 - val_accuracy: 0.8700\n",
            "Epoch 6/100\n",
            "2000/2000 [==============================] - 0s 65us/sample - loss: 0.2272 - accuracy: 0.9250 - val_loss: 0.2544 - val_accuracy: 0.8700\n",
            "Epoch 7/100\n",
            "2000/2000 [==============================] - 0s 62us/sample - loss: 0.2222 - accuracy: 0.9240 - val_loss: 0.2498 - val_accuracy: 0.8750\n",
            "Epoch 8/100\n",
            "2000/2000 [==============================] - 0s 66us/sample - loss: 0.2183 - accuracy: 0.9240 - val_loss: 0.2461 - val_accuracy: 0.8800\n",
            "Epoch 9/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.2152 - accuracy: 0.9250 - val_loss: 0.2432 - val_accuracy: 0.8750\n",
            "Epoch 10/100\n",
            "2000/2000 [==============================] - 0s 64us/sample - loss: 0.2127 - accuracy: 0.9240 - val_loss: 0.2407 - val_accuracy: 0.8750\n",
            "Epoch 11/100\n",
            "2000/2000 [==============================] - 0s 65us/sample - loss: 0.2107 - accuracy: 0.9240 - val_loss: 0.2387 - val_accuracy: 0.8750\n",
            "Epoch 12/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.2089 - accuracy: 0.9250 - val_loss: 0.2370 - val_accuracy: 0.8750\n",
            "Epoch 13/100\n",
            "2000/2000 [==============================] - 0s 64us/sample - loss: 0.2075 - accuracy: 0.9250 - val_loss: 0.2356 - val_accuracy: 0.8750\n",
            "Epoch 14/100\n",
            "2000/2000 [==============================] - 0s 55us/sample - loss: 0.2063 - accuracy: 0.9250 - val_loss: 0.2344 - val_accuracy: 0.8800\n",
            "Epoch 15/100\n",
            "2000/2000 [==============================] - 0s 57us/sample - loss: 0.2052 - accuracy: 0.9255 - val_loss: 0.2333 - val_accuracy: 0.8800\n",
            "Epoch 16/100\n",
            "2000/2000 [==============================] - 0s 62us/sample - loss: 0.2043 - accuracy: 0.9250 - val_loss: 0.2324 - val_accuracy: 0.8800\n",
            "Epoch 17/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.2035 - accuracy: 0.9250 - val_loss: 0.2316 - val_accuracy: 0.8800\n",
            "Epoch 18/100\n",
            "2000/2000 [==============================] - 0s 62us/sample - loss: 0.2028 - accuracy: 0.9260 - val_loss: 0.2309 - val_accuracy: 0.8800\n",
            "Epoch 19/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.2022 - accuracy: 0.9260 - val_loss: 0.2303 - val_accuracy: 0.8800\n",
            "Epoch 20/100\n",
            "2000/2000 [==============================] - 0s 55us/sample - loss: 0.2017 - accuracy: 0.9255 - val_loss: 0.2297 - val_accuracy: 0.8800\n",
            "Epoch 21/100\n",
            "2000/2000 [==============================] - 0s 57us/sample - loss: 0.2012 - accuracy: 0.9260 - val_loss: 0.2293 - val_accuracy: 0.8800\n",
            "Epoch 22/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.2008 - accuracy: 0.9260 - val_loss: 0.2288 - val_accuracy: 0.8800\n",
            "Epoch 23/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.2004 - accuracy: 0.9260 - val_loss: 0.2285 - val_accuracy: 0.8800\n",
            "Epoch 24/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.2001 - accuracy: 0.9260 - val_loss: 0.2281 - val_accuracy: 0.8800\n",
            "Epoch 25/100\n",
            "2000/2000 [==============================] - 0s 68us/sample - loss: 0.1998 - accuracy: 0.9260 - val_loss: 0.2278 - val_accuracy: 0.8800\n",
            "Epoch 26/100\n",
            "2000/2000 [==============================] - 0s 68us/sample - loss: 0.1995 - accuracy: 0.9260 - val_loss: 0.2276 - val_accuracy: 0.8800\n",
            "Epoch 27/100\n",
            "2000/2000 [==============================] - 0s 60us/sample - loss: 0.1993 - accuracy: 0.9265 - val_loss: 0.2273 - val_accuracy: 0.8800\n",
            "Epoch 28/100\n",
            "2000/2000 [==============================] - 0s 62us/sample - loss: 0.1991 - accuracy: 0.9265 - val_loss: 0.2271 - val_accuracy: 0.8800\n",
            "Epoch 29/100\n",
            "2000/2000 [==============================] - 0s 60us/sample - loss: 0.1989 - accuracy: 0.9265 - val_loss: 0.2269 - val_accuracy: 0.8800\n",
            "Epoch 30/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1987 - accuracy: 0.9265 - val_loss: 0.2267 - val_accuracy: 0.8800\n",
            "Epoch 31/100\n",
            "2000/2000 [==============================] - 0s 62us/sample - loss: 0.1985 - accuracy: 0.9265 - val_loss: 0.2266 - val_accuracy: 0.8800\n",
            "Epoch 32/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1984 - accuracy: 0.9265 - val_loss: 0.2264 - val_accuracy: 0.8800\n",
            "Epoch 33/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1982 - accuracy: 0.9265 - val_loss: 0.2263 - val_accuracy: 0.8800\n",
            "Epoch 34/100\n",
            "2000/2000 [==============================] - 0s 53us/sample - loss: 0.1981 - accuracy: 0.9265 - val_loss: 0.2262 - val_accuracy: 0.8800\n",
            "Epoch 35/100\n",
            "2000/2000 [==============================] - 0s 53us/sample - loss: 0.1980 - accuracy: 0.9265 - val_loss: 0.2261 - val_accuracy: 0.8800\n",
            "Epoch 36/100\n",
            "2000/2000 [==============================] - 0s 54us/sample - loss: 0.1979 - accuracy: 0.9265 - val_loss: 0.2260 - val_accuracy: 0.8800\n",
            "Epoch 37/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.1978 - accuracy: 0.9265 - val_loss: 0.2259 - val_accuracy: 0.8800\n",
            "Epoch 38/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1977 - accuracy: 0.9265 - val_loss: 0.2258 - val_accuracy: 0.8800\n",
            "Epoch 39/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.1976 - accuracy: 0.9265 - val_loss: 0.2257 - val_accuracy: 0.8800\n",
            "Epoch 40/100\n",
            "2000/2000 [==============================] - 0s 70us/sample - loss: 0.1976 - accuracy: 0.9265 - val_loss: 0.2256 - val_accuracy: 0.8800\n",
            "Epoch 41/100\n",
            "2000/2000 [==============================] - 0s 60us/sample - loss: 0.1975 - accuracy: 0.9265 - val_loss: 0.2256 - val_accuracy: 0.8800\n",
            "Epoch 42/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1974 - accuracy: 0.9265 - val_loss: 0.2255 - val_accuracy: 0.8800\n",
            "Epoch 43/100\n",
            "2000/2000 [==============================] - 0s 58us/sample - loss: 0.1974 - accuracy: 0.9265 - val_loss: 0.2255 - val_accuracy: 0.8800\n",
            "Epoch 44/100\n",
            "2000/2000 [==============================] - 0s 67us/sample - loss: 0.1973 - accuracy: 0.9265 - val_loss: 0.2254 - val_accuracy: 0.8800\n",
            "Epoch 45/100\n",
            "2000/2000 [==============================] - 0s 54us/sample - loss: 0.1973 - accuracy: 0.9265 - val_loss: 0.2254 - val_accuracy: 0.8800\n",
            "Epoch 46/100\n",
            "2000/2000 [==============================] - 0s 58us/sample - loss: 0.1972 - accuracy: 0.9265 - val_loss: 0.2254 - val_accuracy: 0.8800\n",
            "Epoch 47/100\n",
            "2000/2000 [==============================] - 0s 56us/sample - loss: 0.1972 - accuracy: 0.9265 - val_loss: 0.2253 - val_accuracy: 0.8800\n",
            "Epoch 48/100\n",
            "2000/2000 [==============================] - 0s 66us/sample - loss: 0.1972 - accuracy: 0.9265 - val_loss: 0.2253 - val_accuracy: 0.8800\n",
            "Epoch 49/100\n",
            "2000/2000 [==============================] - 0s 64us/sample - loss: 0.1971 - accuracy: 0.9265 - val_loss: 0.2253 - val_accuracy: 0.8800\n",
            "Epoch 50/100\n",
            "2000/2000 [==============================] - 0s 57us/sample - loss: 0.1971 - accuracy: 0.9270 - val_loss: 0.2252 - val_accuracy: 0.8800\n",
            "Epoch 51/100\n",
            "2000/2000 [==============================] - 0s 56us/sample - loss: 0.1971 - accuracy: 0.9265 - val_loss: 0.2252 - val_accuracy: 0.8800\n",
            "Epoch 52/100\n",
            "2000/2000 [==============================] - 0s 56us/sample - loss: 0.1970 - accuracy: 0.9265 - val_loss: 0.2252 - val_accuracy: 0.8800\n",
            "Epoch 53/100\n",
            "2000/2000 [==============================] - 0s 56us/sample - loss: 0.1970 - accuracy: 0.9265 - val_loss: 0.2252 - val_accuracy: 0.8800\n",
            "Epoch 54/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.1970 - accuracy: 0.9265 - val_loss: 0.2251 - val_accuracy: 0.8800\n",
            "Epoch 55/100\n",
            "2000/2000 [==============================] - 0s 65us/sample - loss: 0.1970 - accuracy: 0.9265 - val_loss: 0.2251 - val_accuracy: 0.8800\n",
            "Epoch 56/100\n",
            "2000/2000 [==============================] - 0s 62us/sample - loss: 0.1969 - accuracy: 0.9265 - val_loss: 0.2251 - val_accuracy: 0.8800\n",
            "Epoch 57/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1969 - accuracy: 0.9265 - val_loss: 0.2251 - val_accuracy: 0.8800\n",
            "Epoch 58/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1969 - accuracy: 0.9265 - val_loss: 0.2251 - val_accuracy: 0.8800\n",
            "Epoch 59/100\n",
            "2000/2000 [==============================] - 0s 55us/sample - loss: 0.1969 - accuracy: 0.9265 - val_loss: 0.2251 - val_accuracy: 0.8800\n",
            "Epoch 60/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.1969 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 61/100\n",
            "2000/2000 [==============================] - 0s 57us/sample - loss: 0.1969 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 62/100\n",
            "2000/2000 [==============================] - 0s 64us/sample - loss: 0.1968 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 63/100\n",
            "2000/2000 [==============================] - 0s 57us/sample - loss: 0.1968 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 64/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1968 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 65/100\n",
            "2000/2000 [==============================] - 0s 65us/sample - loss: 0.1968 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 66/100\n",
            "2000/2000 [==============================] - 0s 56us/sample - loss: 0.1968 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 67/100\n",
            "2000/2000 [==============================] - 0s 66us/sample - loss: 0.1968 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 68/100\n",
            "2000/2000 [==============================] - 0s 57us/sample - loss: 0.1968 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 69/100\n",
            "2000/2000 [==============================] - 0s 57us/sample - loss: 0.1968 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 70/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1968 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 71/100\n",
            "2000/2000 [==============================] - 0s 62us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 72/100\n",
            "2000/2000 [==============================] - 0s 72us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 73/100\n",
            "2000/2000 [==============================] - 0s 66us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 74/100\n",
            "2000/2000 [==============================] - 0s 57us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 75/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 76/100\n",
            "2000/2000 [==============================] - 0s 57us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 77/100\n",
            "2000/2000 [==============================] - 0s 57us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 78/100\n",
            "2000/2000 [==============================] - 0s 64us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 79/100\n",
            "2000/2000 [==============================] - 0s 57us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 80/100\n",
            "2000/2000 [==============================] - 0s 65us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 81/100\n",
            "2000/2000 [==============================] - 0s 67us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 82/100\n",
            "2000/2000 [==============================] - 0s 67us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 83/100\n",
            "2000/2000 [==============================] - 0s 58us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 84/100\n",
            "2000/2000 [==============================] - 0s 64us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 85/100\n",
            "2000/2000 [==============================] - 0s 56us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 86/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 87/100\n",
            "2000/2000 [==============================] - 0s 59us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 88/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 89/100\n",
            "2000/2000 [==============================] - 0s 66us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 90/100\n",
            "2000/2000 [==============================] - 0s 56us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 91/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 92/100\n",
            "2000/2000 [==============================] - 0s 54us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 93/100\n",
            "2000/2000 [==============================] - 0s 56us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 94/100\n",
            "2000/2000 [==============================] - 0s 62us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 95/100\n",
            "2000/2000 [==============================] - 0s 56us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 96/100\n",
            "2000/2000 [==============================] - 0s 55us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 97/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 98/100\n",
            "2000/2000 [==============================] - 0s 63us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 99/100\n",
            "2000/2000 [==============================] - 0s 59us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n",
            "Epoch 100/100\n",
            "2000/2000 [==============================] - 0s 61us/sample - loss: 0.1967 - accuracy: 0.9265 - val_loss: 0.2250 - val_accuracy: 0.8800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5b7480ea00>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BHMxYZLa5FGu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}